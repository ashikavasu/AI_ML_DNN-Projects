# -*- coding: utf-8 -*-
"""synthetic data eczema.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YysBobxQ_1j5_QZLo6flaUGnZHgDjYl4
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install rembg
!pip install rembg[gpu]

!pip install --ignore-installed Pillow==9.3.0

import PIL
PIL.__version__

"""**BACKGROUND REMOVAL **"""

from rembg import remove

input_path = '/content/drive/MyDrive/group project/ezcema/B2qPMqEAPEB_1.jpg'
output_path = 'output.png'

with open(input_path, 'rb') as i:
    with open(output_path, 'wb') as o:
        input = i.read()
        output = remove(input)
        o.write(output)

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
output_image = mpimg.imread(output_path)
plt.imshow(output_image)
plt.axis('off')
plt.show()

"""AUTO CROPPING"""

from PIL import Image

def crop_image(input_path, output_path, crop_size):
    # Open the input image
    image = Image.open(input_path)

    # Get the dimensions of the input image
    width, height = image.size

    # Calculate the crop boundaries
    left = (width - crop_size) // 2
    upper = (height - crop_size) // 2
    right = left + crop_size
    lower = upper + crop_size

    # Crop the image
    cropped_image = image.crop((left, upper, right, lower))

    # Save the cropped image
    cropped_image.save(output_path)

if __name__ == "__main__":
    input_path = '/content/drive/MyDrive/group project/ezcema/B2qPMqEAPEB_1.jpg'
    output_path = 'cropped_image.png'
    crop_size = 300

    # Crop the image
    crop_image(input_path, output_path, crop_size)

    # Display the cropped image
    cropped_image = Image.open(output_path)
    cropped_image.show('B2qPMqEAPEB_1.jpg')

"""DATA AUGMENTATION"""

!pip install Augmentor

import Augmentor
p = Augmentor.Pipeline("/content/drive/MyDrive/group project/eczema sample")



p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)
p.zoom(probability=0.5, min_factor=1.1, max_factor=1.5)
p.flip_left_right(probability=0.5)
p.flip_top_bottom(probability=0.5)
p.crop_random(probability=1, percentage_area=0.5)

p.sample(300)

"""ADVANCED DATA AUGMENTATION"""

import os
import torch
import torchvision.transforms as transforms
from torchvision.utils import save_image
from PIL import Image
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload

# Define your Google Drive folder ID
folder_id = "your_folder_id"

# Create a Google Drive API service
drive_service = build('drive', 'v3')

def augment_medical_images(images, save_dir, num_augmentations=10, output_size=(300, 300)):
    # Define the augmentation transforms
    transform = transforms.Compose([
        transforms.RandomHorizontalFlip(), # Randomly flip horizontally
        transforms.RandomVerticalFlip(),# Randomly flip vertically
        transforms.RandomRotation(20), # Randomly rotate by up to 90 degrees
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),# Adjust color
        transforms.RandomAffine(0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),# Affine transformations
        transforms.ToTensor()
    ])

    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    augmented_images = []
    for i, image_path in enumerate(images):
        image = Image.open(image_path).convert("RGB")
        for j in range(num_augmentations):
            augmented_image = transform(image)# Apply the defined transformations
            augmented_image = transforms.Resize(output_size)(augmented_image) # Resize the image
            augmented_images.append(augmented_image)
            save_image(augmented_image, f'{save_dir}/augmented_{i}_{j}.jpg') # Save augmented image
            upload_image_to_drive(f'{save_dir}/augmented_{i}_{j}.jpg', folder_id)  # Upload to Google Drive

    return torch.stack(augmented_images)

def upload_image_to_drive(file_path, folder_id):
    file_metadata = {
        'name': os.path.basename(file_path),
        'parents': ['1YMgfP-GSzdHaakkGIBhlmUzThWvMwxSY'] # Specify the parent folder in Google Drive
    }
    media = MediaFileUpload(file_path)
    drive_service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id'
    ).execute()

# Example usage
image_dir = "/content/drive/MyDrive/group project/eczema sample"
image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir)]
augmented_images = augment_medical_images(image_files, save_dir='augmented_images', num_augmentations=10)

!pip install numpy opencv-python glob2 matplotlib scikit-learn tensorflow

"""# **Import TensorFlow and Other Libraries**"""

import os
import numpy as np
import cv2
from glob import glob
from matplotlib import pyplot
import matplotlib.pyplot as plt
from sklearn.utils import shuffle
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

IMG_H = 64
IMG_W = 64
IMG_C = 3

w_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)

"""# **Loading and Preparing Dataset**"""

def load_image(image_path):
    img = tf.io.read_file(image_path)
    img = tf.image.decode_jpeg(img, channels=3)  # Decoding as RGB image
    img = tf.image.resize(img, (IMG_H, IMG_W))
    img = tf.cast(img, tf.float32)  # Casting the image to float32
    img = (img - 127.5) / 127.5  # Normalizing pixel values to the range [-1, 1]
    return img

def tf_dataset(images_path, batch_size):
     dataset = tf.data.Dataset.from_tensor_slices(images_path)
     dataset = dataset.shuffle(buffer_size=10240)
     dataset = dataset.map(load_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)
     dataset = dataset.batch(batch_size)
     dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)

     return dataset

"""# **Transpose Convolution Blocks**"""

def deconv_block(inputs, num_filters, kernel_size, strides, bn=True):
    x = Conv2DTranspose(
        filters=num_filters,
        kernel_size=kernel_size,
        kernel_initializer=w_init,
        padding="same",
        strides=strides,
        use_bias=False
    )(inputs)

    if bn:
         x = BatchNormalization()(x)
         x = LeakyReLU(alpha=0.2)(x)
    return x

def conv_block(inputs, num_filters, kernel_size, padding="same", strides=2, activation=True):
    x = Conv2D(
        filters=num_filters,
        kernel_size=kernel_size,
        kernel_initializer=w_init,
        padding=padding,
        strides=strides,
    )(inputs)
    if activation:
         x = LeakyReLU(alpha=0.2)(x)
         x = Dropout(0.3)(x)
    return x

"""# **Building The Generator**"""

def build_generator(latent_dim):
    f = [2**i for i in range(5)][::-1]
    filters = 32
    output_strides = 16
    h_output = IMG_H // output_strides
    w_output = IMG_W // output_strides
    noise = Input(shape=(latent_dim,), name="generator_noise_input")
    x = Dense(f[0] * filters * h_output * w_output, use_bias=False)(noise)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Reshape((h_output, w_output, 16 * filters))(x)
    for i in range(1, 5):
        x = deconv_block(x,
            num_filters=f[i] * filters,
            kernel_size=5,
            strides=2,
            bn=True
        )
    x = conv_block(x,
        num_filters=3,
        kernel_size=5,
        strides=1,
        activation=False
    )
    fake_output = Activation("tanh")(x)
    return Model(noise, fake_output, name="generator")

"""# **Building The Discriminator**"""

def build_discriminator():
    f = [2**i for i in range(4)]
    image_input = Input(shape=(IMG_H, IMG_W, IMG_C))
    x = image_input
    filters = 64
    output_strides = 16
    h_output = IMG_H // output_strides
    w_output = IMG_W // output_strides
    for i in range(0, 4):
        x = conv_block(x, num_filters=f[i] * filters, kernel_size=5, strides=2)
    x = Flatten()(x)
    x = Dense(1)(x)
    return Model(image_input, x, name="discriminator")

"""# **Completing DCGAN Model**"""

class GAN(Model):
    def __init__(self, discriminator, generator, latent_dim):
        super(GAN, self).__init__()
        self.discriminator = discriminator
        self.generator = generator
        self.latent_dim = latent_dim

    def compile(self, d_optimizer, g_optimizer, loss_fn):
        super(GAN, self).compile()
        self.d_optimizer = d_optimizer
        self.g_optimizer = g_optimizer
        self.loss_fn = loss_fn

    def train_step(self, real_images):
        batch_size = tf.shape(real_images)[0]

        for _ in range(2):
            ## Training the discriminator
            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))
            generated_images = self.generator(random_latent_vectors)
            generated_labels = tf.zeros((batch_size, 1))
            with tf.GradientTape() as ftape:
                predictions = self.discriminator(generated_images)
                d1_loss = self.loss_fn(generated_labels, predictions)
            grads = ftape.gradient(d1_loss, self.discriminator.trainable_weights)
            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))

            ## Training the discriminator
            labels = tf.ones((batch_size, 1))
            with tf.GradientTape() as rtape:
                predictions = self.discriminator(real_images)
                d2_loss = self.loss_fn(labels, predictions)
            grads = rtape.gradient(d2_loss, self.discriminator.trainable_weights)
            self.d_optimizer.apply_gradients(zip(grads, self.discriminator.trainable_weights))

            ## Training the generator
            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))
            misleading_labels = tf.ones((batch_size, 1))
            with tf.GradientTape() as gtape:
                predictions = self.discriminator(self.generator(random_latent_vectors))
                g_loss = self.loss_fn(misleading_labels, predictions)
            grads = gtape.gradient(g_loss, self.generator.trainable_weights)
            self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))

        return {"d1_loss": d1_loss, "d2_loss": d2_loss, "g_loss": g_loss}

"""# **Saving Image**"""

def save_plot(examples, epoch, n):
    examples = (examples + 1) / 2.0
    for i in range(n * n):
        pyplot.subplot(n, n, i+1)
        pyplot.axis("off")
        pyplot.imshow(examples[i])
    if not os.path.exists('samples'):
        os.makedirs('samples')
    current_dir = os.getcwd()
    filename = f"{current_dir}/samples/generated_plot_epoch-{epoch+1}.png"
    pyplot.savefig(filename)
    pyplot.close()

tf.config.run_functions_eagerly(True)

"""# **Running The Code**"""

if __name__ == "__main__":
    ## Hyperparameters
    batch_size = 128
    latent_dim = 128
    num_epochs = 100
    drive_path = '/content/drive/MyDrive/group project/augmented eczema images'  # Mounting Google Drive path
    data_folder = 'augmented eczema images'  # Image data folder name

    # Constructing the complete image data path
    image_data_folder = drive_path + '/'
    images_path = glob(image_data_folder + '*')  # List of image file paths
    d_model = build_discriminator()
    g_model = build_generator(latent_dim)
    # d_model.load_weights("saved_model/d_model.h5")
    # g_model.load_weights("saved_model/g_model.h5")
    d_model.summary()
    g_model.summary()
    gan = GAN(d_model, g_model, latent_dim)
    bce_loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True, label_smoothing=0.1)
    d_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
    g_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
    gan.compile(d_optimizer, g_optimizer, bce_loss_fn)
    images_dataset = tf_dataset(images_path, batch_size)

    for epoch in range(num_epochs):
        gan.fit(images_dataset, epochs=1)
        g_model.save("saved_model/g_model.h5")
        d_model.save("saved_model/d_model.h5")

        if (epoch + 1) % 10 == 0:  # Change 10 to the desired frequency
            n_samples = 25
            noise = np.random.normal(size=(n_samples, latent_dim))
            examples = g_model.predict(noise)

            examples = (examples + 1) / 2.0  # Convert back to [0, 1] range
            save_plot(examples, epoch, int(np.sqrt(n_samples)))

            plt.figure(figsize=(10, 10))
            for i in range(n_samples):
                plt.subplot(5, 5, i+1)
                plt.axis("off")
                plt.imshow(examples[i])
            plt.tight_layout()
            plt.show()

from google.colab import drive
drive.mount('/content/drive')

"""# **FID Validation - Frechect Inception Distance Validation**"""

pip install tensorflow tensorflow-gan pillow scipy

"""# **FID(Frechet Inception Distance) Calculation**"""

import numpy as np
import tensorflow as tf
import tensorflow_gan as tfgan
from scipy.linalg import sqrtm

def calculate_fid(real_images, generated_images, batch_size, model=None):
    if model is None:
        model = tfgan.eval.run_inception(images=real_images, output_tensor='pool_3:0')
    # Generate features for real and generated images
    real_features = model.predict(tf.image.resize(real_images, (299, 299)))
    gen_features = model.predict(tf.image.resize(generated_images, (299, 299)))

   # Calculate mean and covariance for real and generated features
    m1, m2 = np.mean(real_features, axis=0), np.mean(gen_features, axis=0)
    s1, s2 = np.cov(real_features, rowvar=False), np.cov(gen_features, rowvar=False)

   # Calculate mean and covariance for real and generated features
    diff = np.sum((m1 - m2)**2) + np.trace(s1 + s2 - 2*np.dot(sqrtm(np.dot(s1, s2)), s1))

    return np.sqrt(diff)  # returning the computed difference

"""# **IS(Inception Score) Calculation**"""

import tensorflow_gan as tfgan
from tensorflow.keras.applications.inception_v3 import InceptionV3
from scipy.stats import entropy

def calculate_inception_score(images, inception_model, batch_size=32, num_splits=10,epsilon=1e-10):
    preds = []
    for i in range(num_splits):
        subset = images[i * (len(images) // num_splits):(i + 1) * (len(images) // num_splits)]
        pred = inception_model.predict(subset)  # To predict class probabilities for the subset
        preds.append(pred)
    preds = np.concatenate(preds)   # Combine predictions from all subsets

    p_yx = np.mean(preds, axis=0) # Calculate the average class probabilities across all predictions
    kl_divs = np.sum(preds * (np.log(preds + epsilon) - np.log(p_yx + epsilon)), axis=1) # Calculate the Kullback-Leibler (KL) divergences for each prediction
    inception_score = np.exp(np.mean(kl_divs))  # Calculate the exponential of the mean of KL divergences to obtain Inception Score


    return inception_score #Returning the inception score

"""# **Validating the FID and Inception Score**"""

inception_model = tf.keras.applications.InceptionV3(include_top=False, pooling='avg', input_shape=(299, 299, 3))

for epoch in range(num_epochs):
    gan.fit(images_dataset, epochs=1)
    # g_model.save("saved_model/g_model.h5")
    # d_model.save("saved_model/d_model.h5")
    if (epoch + 1) % 1 == 0:
        n_samples = 1000
        noise = np.random.normal(size=(n_samples, latent_dim))
        generated_images = (g_model.predict(noise) + 1) / 2.0

        #real images from tensor to numpy
        real_images_numpy = []
        for real_images_batch in images_dataset:
            real_images_numpy.append(real_images_batch.numpy())
        real_images_numpy = np.concatenate(real_images_numpy, axis=0)

        fid_score = calculate_fid(real_images_numpy, generated_images, batch_size, model=inception_model)
        print(f"FID Score at epoch {epoch + 1}: {fid_score}")

        # Resize generated images to (299, 299, 3)
        resized_generated_images = []
        for img in generated_images:
            resized_img = tf.image.resize(img, (299, 299))
            resized_generated_images.append(resized_img.numpy())
        resized_generated_images = np.array(resized_generated_images)

        inception_score = calculate_inception_score(resized_generated_images, inception_model)
        print(f"Inception Score at epoch {epoch + 1}: {inception_score}")

"""# **Visual inspection Plot**"""

import matplotlib.pyplot as plt
import numpy as np

# Define the dimensions of the grid
grid_rows = 4
grid_cols = 4

# Create a figure and a grid of subplots
fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(10, 10))

# Loop to populate the subplots with generated images
for i, ax in enumerate(axes.flat):
    if i < len(generated_images):
        generated_img = generated_images[i]
        ax.imshow(generated_img)
        ax.axis('off')
    else:
        ax.axis('off')

plt.tight_layout()
plt.show()

"""# **Performance measuring Gaussian mixture model**"""

import numpy as np
from sklearn.mixture import GaussianMixture
import matplotlib.pyplot as plt

# Combine real and generated images for GMM fitting
combined_images = np.concatenate((real_images_numpy.flatten(), generated_images.flatten()))

# Reshape the data to a single column (required by GMM)
combined_images = combined_images.reshape(-1, 1)

# Fit a Gaussian Mixture Model to the combined images
n_components = 2
gmm = GaussianMixture(n_components=n_components)
gmm.fit(combined_images)

# Get the GMM means and covariances for each component
gmm_means = gmm.means_.flatten()
gmm_covariances = np.sqrt(gmm.covariances_).flatten()

# Visualize the GMM components
plt.figure(figsize=(8, 6))
plt.scatter(combined_images, np.zeros_like(combined_images), marker='.', color='gray', alpha=0.3)
for mean, cov in zip(gmm_means, gmm_covariances):
    x = np.linspace(mean - 3 * cov, mean + 3 * cov, 100)
    y = np.exp(-0.5 * ((x - mean) / cov) ** 2) / (cov * np.sqrt(2 * np.pi))
    plt.plot(x, y, label=f'Component Mean: {mean:.2f}, Covariance: {cov:.2f}')
plt.xlabel('Pixel Value')
plt.ylabel('Density')
plt.legend()
plt.title('Gaussian Mixture Model Components')
plt.show()
