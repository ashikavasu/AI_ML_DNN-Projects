# -*- coding: utf-8 -*-
"""Final_ML_project.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_gFvqQ9MKLMBtHjJK8pok_pfI_N8kr3M

**PROJECT PLAN**

The problem statement is that humans need to be detected in images or videos, and the goal is to find the accuracy of the trained model in detecting pedestrians, including the specific features and functions. I performed a color segmentation and accessed the quality of an image dataset by manipulating the images. Also, here I used three models by comparing their accuracies to find better performance and preprocessed the data, and normalized it before training/testing the model.

**SYSTEM DESIGN AND IMPLEMENTATION STRATEGY**

The dataset, the trained model, and any other pertinent data are stored in storage, while operations and data organising are carried out using hardware components such the GPU and CPU. For cleaning, preprocessing, and enhancing the training data, software components like OpenCV or NumPy are employed. Matplotlib or OpenCV are two examples of visualisation tools that are used to display the outcomes of the human detection system. Resizing, normalising, and changing the colour space are all part of the preprocessing and cleaning of the collected photos or video. To make the training data more diverse, preprocessed data is subjected to data augmentation techniques including rotation, scaling, and flipping.Here, used the non-max suppression algorithm to remove duplicate detections and select the most relevant bounding boxes.

To read a directory's contents as a collection of images.
Also i tried using pathlib library to read a images from the directory.
"""

# from pathlib import Path
#folder_dir = '/content/drive/MyDrive/pedestrians128x64/' ##get the path/directory
# images = Path(folder_dir).glob('*.ppm')   ##iterate over files in that directory
# for img_rd in images:
#     (img_rd)

from skimage import io
from skimage.io import imread_collection
img_rd = imread_collection('/content/drive/MyDrive/pedestrians128x64/*.ppm')
img_rd

"""Displays the first image in array """

import matplotlib.pyplot as plt
plt.imshow(img_rd[0])

"""
The below code is to perform color segmentation on an image represented in the BGR (Blue-Green-Red) color space.
hsv #255, 0, 0 (red), 255, 128, 0 (orange),255, 153, 255(pink)"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

hsv = cv2.cvtColor(img_rd[0], cv2.COLOR_BGR2HSV)
cv2_imshow(hsv)
lower_range = np.array([110,50,50])
upper_range = np.array([130,255,255])
mask = cv2.inRange(hsv, lower_range, upper_range)

cv2_imshow(mask)

"""For each image, the code converts the image from the default BGR color space to grayscale and then stores the grayscale version of the image in the positive_patches and displaying the first ten images in the set."""

# Use the cvtColor() function to grayscale the image
length= len(img_rd)
f,axes = plt.subplots(1,10,figsize=(15,2))
positive_patches = np.zeros(shape=(925,128,64))
for i in range(0,length):
  gray_image = cv2.cvtColor(img_rd[i], cv2.COLOR_BGR2GRAY)
  positive_patches[i,:,:] = gray_image
  if i < 10:
     img = positive_patches[i]
     gray = axes[i].imshow(img,cmap='gray')

"""**ASSESS THE QUALITY OF AN IMAGE**

There are few points to assess the quality of an image dataset such as,Load the image dataset, check the dimensions of the dataset using the shape attribute of the image object, and visualise it. Then Check the distribution of pixel values in the image and the image resolution using functions such as resize(), crop(), or filter().

Here, calculating the histogram of a grayscale image with ravel() is often used to flatten the histogram array and then display it.
"""

hist = cv2.calcHist(img_rd[0],[0],None,[256],[0,256])
plt.hist(gray_image.ravel(),256,[0,256])
plt.show()
print("imageshape -",gray_image.shape)

"""Using a combination of OpenCV and the Python Imaging Library (PIL) to manipulate images.
Resize an image from OpenCV. 
Next, open an image file and then crop the original,resize it, and save both the images.

The difference is OpenCV has a broader focus on computer vision and image processing tasks, while Pillow is more specialized for image manipulation and editing. 
"""

from PIL import Image
print("resized image using CV")
resizing = cv2.resize(img_rd[1], (200,200))
cv2_imshow(resizing)
img = Image.open('/content/drive/MyDrive/pedestrians128x64/per00001.ppm')
print("resized image using PIL")
resized_img = img.resize((200,200))              ##Resize the image to a new width and height
resized_img.save('resized.jpg')                  ##Save the resized image
resized_img.show()
print("Crop the image to a specific region")
cropped_img = img.crop((50, 100, 65, 200))       ##The coordinates are (left, upper, right, lower)
cropped_img.save('cropped.jpg') 
cropped_img.show()

"""The below code is to perform image manipulation by rotating an image by 90 degrees clockwise,flipping it horizontally and vertically, and then displaying and saving it. """

img_rotated = img.rotate(90)
img_flipped = img.transpose(Image.FLIP_LEFT_RIGHT) # Flip the image horizontally
img_flipped_vert = img.transpose(Image.FLIP_TOP_BOTTOM) # Flip the image vertically
# Display the original, rotated, and flipped images
img.show() 
img_rotated.show()
img_flipped.show()
img_flipped_vert.show()
# Save the rotated and flipped images to disk
img_rotated.save("example_rotated.jpg")
img_flipped.save("example_flipped.jpg")
img_flipped_vert.save("example_flipped_vert.jpg")

"""cropped the image using NumPy array slicing"""

img1 = cv2.imread('/content/drive/MyDrive/pedestrians128x64/per00001.ppm')
x, y, w, h = 10, 10,40,60          # Define the coordinates of the crop area
crop_img = img1[y:y+h, x:x+w]      # Crop the image
cv2_imshow(crop_img)               # Display the cropped image

"""**Noise reduction using filter**

The median filter is a nonlinear filter that replaces the value of a pixel with its median value and preserves edges in an image, so it is not effective in removing Gaussian noise. But, the Gaussian filter is a linear filter that is useful for smoothing an image and reducing noise as it can blur edges and fine details in an image.Also, it will help to improve edge detection.
"""

from skimage import io, filters
smooth_image = filters.gaussian(gray_image, sigma=1)
median = cv2.medianBlur(img1, 5)
fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(8, 3))

axes[0].imshow(gray_image, cmap='gray')
axes[0].set_title('Original')

axes[1].imshow(smooth_image, cmap='gray')
axes[1].set_title('Smoothed')

axes[2].imshow(median, cmap='gray')
axes[2].set_title('Filtered Image')
for ax in axes:
    ax.axis('off')
plt.tight_layout()
plt.show()

"""NEGATIVE PATCHES

Here, extracting the patches from images to train in a model.
The extract_patches() function is defined to extract patches from an input gray image. The negative_patches variable is defined as a 2D NumPy array that contains 100 patches extracted from each image in the images list for each of the three scale values in the scale_values list. 
"""

from skimage import data, color
from sklearn.feature_extraction.image import PatchExtractor
from skimage import transform
import numpy as np , random
imgs_to_use = ['camera', 'text', 'brick', 'moon',
               'horse', 'clock','eagle','shepp_logan_phantom']

images = [getattr(data, name)() for name in imgs_to_use]
getattr(data, 'text')().shape

scale_values= [0.5, 1.0, 2.0] 
def extract_patches(img, N, scale=random.choice(scale_values), patch_size=gray_image.shape):
    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))
    extractor = PatchExtractor(patch_size=extracted_patch_size,
                               max_patches=N, random_state=0)
    patches = extractor.transform(img[np.newaxis])
    if scale != 1:
        patches = np.array([transform.resize(patch, patch_size)
                            for patch in patches])
    return patches

negative_patches = np.vstack([extract_patches(im, 100)
                              for im in images for scale in [0.5, 1.0, 2.0]])
negative_patches.shape

fig, ax = plt.subplots(6, 10,figsize=(18,18)) 
for i, axi in enumerate(ax.flat):
    axi.imshow(negative_patches[5 * i], cmap='gray')
    axi.axis('off')

"""Displaying the shape and combining both patches """

print("pos_shape - ",positive_patches.shape)
print("neg_shape - ",negative_patches.shape)

import numpy as np
pos_neg =np.concatenate((positive_patches,negative_patches))
print("Total count - ", len(pos_neg))

"""To extract Histogram of Oriented Gradient (HOG) features from a collection of images stored in the pos_neg array. """

from skimage import data,color,feature
X = np.array([feature.hog(img) for img in pos_neg])

"""Below is the code for visualising the HOG feature descriptor computed from a grayscale image (gray_image)"""

hog_vec, hog_vis = feature.hog(gray_image,visualize=True)
fig,ax = plt.subplots(1,2,figsize=(5,3))
ax[0].imshow(gray_image,cmap='gray')
ax[0].set_title('Original Image')
ax[1].imshow(hog_vis)
ax[1].set_title('HOG Feature')
ax[1].axis('off')

"""Here, a binary label vector y is created to match the feature vectors and used to train a binary classifier."""

y = np.zeros(X.shape[0])
y[0:positive_patches.shape[0]] = 1

"""A dataset is splitted into a training set and a test set. """

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y)
X_train

"""
Here, a normalization technique MinMaxScaler is used to scale the input features to a specified range, typically between 0 and 1. """

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train_scale = scaler.fit_transform(X_train)
X_test_scale = scaler.transform(X_test)

"""**SVM MODEL**
 
A support vector machine (SVM) classifier is used for the classification of the scaled training data X_train_scale and y_train. The fit() method of SVC is used to train the model on the scaled training data. Once the model is trained, the score() method is used to evaluate the performance of the model on both the training and test sets and calculate the accuracy of the model by comparing the predicted labels to the actual labels in the input data. The accuracy is the percentage of correctly classified instances in the data. The method takes in the input features X_train_scale and X_test_scale and the corresponding labels Y_train and Y_test. These accuracy values can be used to evaluate the performance of the model and make adjustments as necessary.
"""

from sklearn.svm import SVC
model_svm = SVC()
model_svm.fit(X_train_scale,y_train)
print('Accuracy of SVM classifier on training set: {:.2f}'
     .format(model_svm.score(X_train_scale, y_train)))
print('Accuracy of SVM classifier on test set: {:.2f}'
     .format(model_svm.score(X_test_scale, y_test)))

"""This code is using the trained model_svm to predict the labels for the input features in X_test. The predict() method of SVC is used to predict the class labels for the input data."""

pred_labels_SVM = model_svm.predict(X_test)
print(pred_labels_SVM)

from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, pred_labels_SVM)
print("Accuracy:", accuracy)

"""**Cross validation SVM**

This code performs k-fold cross-validation on the SVM classifier with n_splits=5 is created to split the data into 5 folds. "np.mean" is used to compute the mean of the cross-validation scores.The random_state=42 parameter ensures that the same random splits are used for each run of the code, which makes the results reproducible.
"""

from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score,KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(SVC(), X, y, cv=kfold)
mean_cv_score = np.mean(cv_scores)
print("Cross-validation scores: ", cv_scores)
print("Mean cross-validation score: {:.2f}".format(mean_cv_score))

"""***Confusion matrix for SVM ***

The confusion matrix is for the predictions made by the SVM classifier on the test set, and the resulting data is then plotted using the heatmap function from the Seaborn module. The diagonal elements of the matrix represent the number of correct predictions for each class, while the off-diagonal elements represent the number of incorrect predictions.The code then computes the accuracy, precision, recall, and F1-score of the SVM classifier, which are used to evaluate the performance of the SVM classifier on the test set.
"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# compute the confusion matrix
conf_mx = confusion_matrix(y_test,pred_labels_SVM)
f,ax = plt.subplots(figsize=(5,5))
#Plot the confusion matrix.
sns.heatmap(conf_mx,
            annot=True,
            fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()
 
 
# Finding precision and recall
accuracy = accuracy_score(y_test, pred_labels_SVM)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, pred_labels_SVM)
print("Precision :", precision)
recall = recall_score(y_test, pred_labels_SVM)
print("Recall    :", recall)
F1_score = f1_score(y_test, pred_labels_SVM)
print("F1-score  :", F1_score)

"""ROC curve"""

from sklearn.metrics import roc_curve, auc
fpr, tpr, threshold = roc_curve(y_test, pred_labels_SVM)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='blue', label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random guess')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""**COMPARING WITH KNN AND RANDOM FOREST CLASSIFIERS**

**KNN model**

This code trains a K-Nearest Neighbors (K-NN) classifier on the scaled training data X_train_scale and labels y_train. The score method returns the mean accuracy on the given data and labels.
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier()
knn.fit(X_train_scale, y_train)
print('Accuracy of K-NN classifier on training set: {:.2f}'
     .format(knn.score(X_train_scale, y_train)))
print('Accuracy of K-NN classifier on test set: {:.2f}'
     .format(knn.score(X_test_scale, y_test)))
pred_labels_KNN = knn.predict(X_test)
pred_labels_KNN

accuracy = accuracy_score(y_test, pred_labels_KNN)
print("Accuracy:", accuracy)

"""cross validation for KNN"""

from sklearn.model_selection import cross_val_score,KFold
kfold = KFold(n_splits=5, shuffle=True, random_state=42)
cv_scores = cross_val_score(KNeighborsClassifier(), X, y, cv=kfold)
mean_cv_score = np.mean(cv_scores)
print("Cross-validation scores: ", cv_scores)
print("Mean cross-validation score: {:.2f}".format(mean_cv_score))

"""**Confusion matrix for KNN**"""

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# compute the confusion matrix
conf_mx = confusion_matrix(y_test,pred_labels_KNN)
f,ax = plt.subplots(figsize=(5,5))
#Plot the confusion matrix.
sns.heatmap(conf_mx,
            annot=True,
            fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show() 
# Finding precision and recall
accuracy = accuracy_score(y_test, pred_labels_KNN)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, pred_labels_KNN, zero_division=1)
print("Precision :", precision)
recall = recall_score(y_test, pred_labels_KNN)
print("Recall    :", recall)
F1_score = f1_score(y_test, pred_labels_KNN)
print("F1-score  :", F1_score)

"""ROC curve KNN"""

from sklearn.metrics import roc_curve, auc
fpr, tpr, threshold = roc_curve(y_test, pred_labels_KNN)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='blue', label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random guess')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""**Random Forest Classifier**

RandomForestClassifier for creating the Random Forest model, train_test_split to calculate the accuracy of the model. Also,ensemble learning will combines multiple models to improve the accuracy and robustness of the predictions.
"""

from sklearn.ensemble import RandomForestClassifier
# Instantiate Random Forest Classifier with default parameters
rfc = RandomForestClassifier()
rfc.fit(X_train_scale, y_train)
y_pred = rfc.predict(X_test)
print('Accuracy of RFC classifier on training set: {:.2f}'
     .format(rfc.score(X_train_scale, y_train)))
print('Accuracy of RFC classifier on test set: {:.2f}'
     .format(rfc.score(X_test_scale, y_test)))

"""Accuracy"""

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.metrics import confusion_matrix
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
# compute the confusion matrix
conf_mx = confusion_matrix(y_test,y_pred)
f,ax = plt.subplots(figsize=(5,5))
#Plot the confusion matrix.
sns.heatmap(conf_mx,
            annot=True,
            fmt='g')
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()
# Finding precision and recall
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, y_pred, zero_division=1)
print("Precision :", precision)
recall = recall_score(y_test, y_pred)
print("Recall    :", recall)
F1_score = f1_score(y_test, y_pred)
print("F1-score  :", F1_score)

"""ROC curve RFC"""

from sklearn.metrics import roc_curve, auc
fpr, tpr, threshold = roc_curve(y_test, y_pred)
roc_auc = auc(fpr, tpr)
plt.plot(fpr, tpr, color='blue', label='ROC curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='red', linestyle='--', label='Random guess')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.0])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()

"""**Comparing the model**

According to speed and models accuracy, SVM can be slower than KNN and random forests since they require solving a convex optimisation problem, but for large datasets, KNN can be slower due to the need to compute distances between all pairs of data points. Random forests can be fast for both small and large datasets since they can be parallelized and do not require solving an optimisation problem. KNN can perform well for small datasets or when the data has a simple structure. Random forests can be effective when dealing with noisy or missing data and can perform well on large datasets. SVM, KNN, and Random Forest classifiers  accuracies on training and testing data are 1,0,98,1.

As per this dataset,
SVM
Accuracy = 0.7,
Precision score = 1.0
Recall = 1.0
F1 score: 0.95
ROC curve = good
auc =0.96

KNN
Accuracy = 0.7
Precision score is 1.0.
Recall = 0.0
F1 score = 0.0
ROC curve = bad
auc =0.5

RFC
Accuracy = 0.7
Precision score is 1.0.
recall = 0.13
F1 score = 0.23
ROC curve = bad
auc =0.5

By comparing the above models of the confusion matrix, ROC curve, and auc, SVM has better performance than the other two models.

**Removing the small noises by some operations**

Apply erosion to the image to remove small, isolated noise pixels by shrinking the boundaries of the foreground objects, and apply dilation to the eroded image to fill in small holes and gaps in the image.
"""

kernel = np.ones((3,3), np.uint8) #erosion to remove small isolated noise pixels
eroded = cv2.erode(gray_image, kernel, iterations=1)
dilated = cv2.dilate(eroded, kernel, iterations=1) #dilation to fill in small holes and gaps
cv2_imshow(gray_image)
cv2_imshow(dilated)

"""An opening operation combination of erosion followed by a dilation and is used to remove small noise pixels. 

A closing operation is a combination of a dilation followed by an erosion and is used to fill in small holes and gaps. 
"""

kernel = np.ones((3, 3), np.uint8)#structuring element for the operation
opening = cv2.morphologyEx(gray_image, cv2.MORPH_OPEN, kernel)  #an opening operation to remove small noise pixels
closing = cv2.morphologyEx(gray_image, cv2.MORPH_CLOSE, kernel)  # a closing operation to fill in small holes and gaps
cv2_imshow(gray_image)
cv2_imshow(opening)
cv2_imshow(closing)

""" After fitting the SVM classifier, the code defines a grid of points where the model will be evaluated. The decision boundaries are plotted as a filled contour plot with transparency, and the data points are plotted as a scatter plot using the class labels to determine the colors."""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import make_classification
from sklearn.svm import SVC
X, y = make_classification(n_samples=100, n_features=2, n_redundant=0,
                           n_informative=2, random_state=42, n_clusters_per_class=1)
svm_demo= SVC(kernel='rbf', C=1)   #'rbf' (radial basis function)--handle more complex decision boundaries
svm_demo.fit(X, y)
xx, yy = np.meshgrid(np.linspace(-3, 3, 500), np.linspace(-3, 3, 500))#grid of points where we want to evaluate the model
Z = svm_demo.predict(np.c_[xx.ravel(), yy.ravel()])
Z = Z.reshape(xx.shape)
fig, ax = plt.subplots() # Plot the data points and the decision boundaries
ax.contourf(xx, yy, Z, alpha=0.3)
ax.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='viridis')
plt.show()

"""plotting """

from skimage import io, color
test_image = io.imread('/content/drive/MyDrive/street_video_assessed_test-20230405T222130Z-001/street_video_assessed_test/image_00000033_0.png')
test_gray = color.rgb2gray(test_image)
plt.imshow(test_image)

"""sliding_window takes an input image and generates a sliding window that patches over the image. It will extract patches of an image for detection, feature extraction, and image segmentation. The step size between consecutive patches determines the degree of overlap between adjacent patches"""

def sliding_window (img,h,w,istep=5,jstep=5):
  for i in range(0,img.shape[0]-h,istep):
    for j in range(0,img.shape[1]-w,jstep):
      patch = img[i:i+h,j:j+w]
      yield (i,j),patch
idx, patches =zip(*sliding_window(test_gray,128,64))

"""Here it extracts a set of patches using a sliding window approach for object detection and recognition tasks"""

patches_hog = np.array([feature.hog(patch) for patch in patches])
pred_labels = model_svm.predict(patches_hog)

indices = np.array(idx) #converting to numpy array

pred_labels.shape

indices.shape

"""**NMS(Non max suppression)**

Non-Maximum Suppression (NMS), which is a post-processing step used in object detection tasks to remove duplicate detections and select the most relevant bounding boxes.

The function non_max_suppression takes a list of bounding boxes boxes and a threshold value threshold as input. It uses a while loop to iteratively select the box with the highest confidence score, add it to a list of selected boxes, and remove all other boxes with an overlap area greater than the specified threshold. This process is repeated until all boxes have been processed. The function calculate_overlap calculates the overlap area and overlap ratio between two bounding boxes. The overlap ratio is used to determine which boxes should be removed during NMS.Finally, the non_max_suppression function returns a list of selected bounding boxes, final_boxes.The threshold value used in NMS is often an important hyperparameter to tune in order to achieve optimal performance.

Here, the confidence score of SVM is 0 or 1. Select the sliding window with the highest confidence score. The steps for the NMS algorithm are to select the highest confidence score and sort in descending order. After that, I created an empty list to set the final bounding box values. Delete the highest confidence box and find the IOU with the highest score, then delete those boxes with an IOU greater than the threshold. repeated the process until we had no boxes left and returned the final list of non-overlapping boxes.
   	                                                                          ***IOU=  area of overlap/area of union*** 
"""

def non_max_suppression(boxes, threshold):
    # Sort the boxes in any order
    indices = np.arange(len(boxes))
    boxes = boxes[indices]
    # print(boxes)
    # Initialize an empty list to hold the selected boxes
    selected_boxes = []
    
    # Loop over the boxes and perform NMS
    while len(boxes) > 0:
        # Select the first box and add it to the list of selected boxes
        selected_boxes.append(boxes[0])
        boxx = np.array([(x[0],x[1],x[0]+64,x[1]+128) for x in boxes])
        # Compute the overlap area of the selected box with all other boxes
        overlap = calculate_overlap(selected_boxes[-1], boxx[1:])
        
        # Remove all boxes with an overlap area greater than the specified threshold
        boxes = boxes[1:][overlap < threshold]
    
    return selected_boxes

def calculate_overlap(box, boxes):
    # Calculate the overlap coordinates
    x1 = np.maximum(box[0], boxes[:, 0])
    y1 = np.maximum(box[1], boxes[:, 1])
    x2 = np.minimum(x1+64, boxes[:, 2])
    y2 = np.minimum(y1+128, boxes[:, 3])
    overlap_area = np.maximum(0, x2 - x1) * np.maximum(0, y2 - y1)

    # Calculate the area of the boxes
    box_area = ((x1+64) - box[0]) * ((y1+128) - box[1])
    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])

    # Calculate the overlap ratio
    overlap_ratio = overlap_area / (box_area + boxes_area - overlap_area)

    return overlap_ratio

final_boxes = non_max_suppression(indices[pred_labels==1],0.8)

final_boxes

"""**Plotting**"""

f,ax = plt.subplots(figsize=(10,10))
ax.imshow(test_image)
indices = np.array(idx)
object_count = 0
## plot bounding boxes
for i, j in final_boxes:
    ax.add_patch(plt.Rectangle((j,i),64,128,
                              edgecolor='red',facecolor='none',linewidth=2))
    object_count += 1
#add object count above box
    plt.text(j,i,f"count: {object_count}",fontsize=10,ha='left',verticalalignment='top',color='black',weight='bold')   
print("Detected objects: ", object_count)
plt.show()

"""Here, the code initialises a CSRT (Channel and Spatial Reliability) tracker and initialises it with a bounding box, init_box. It then loops through a sequence of n_frames images and updates the tracker for each image using the tracker.update() method. If the tracker successfully tracks the object in the image, the bounding box coordinates are stored in the boxes array. If the tracker fails the corresponding entry in the boxes array is left as all zeros."""

image = imread_collection('/content/drive/MyDrive/street_video_assessed_test-20230405T222130Z-001/street_video_assessed_test/*.png')
tracker= cv2.TrackerCSRT_create()
init_box = [100,160,64,128]    ##initial bounding box is located at pixel coordinates (100, 160) in the image, with a width and height.
tracker.init(image[0],init_box)
n_frames = 50
import numpy as np
boxes = np.zeros((n_frames,4),dtype='int')

for i in range(1,n_frames):
  ok,box = tracker.update(image[i])
  if ok :
    boxes[i-1]=box

boxes

"""The top-left and bottom-right coordinates of the rectangle are defined by (ini_top, ini_left) and (ini_bottom, ini_right), respectively."""

ini_top= init_box[0]
ini_left = init_box[1]
ini_bottom = init_box[0] + init_box[2]
ini_right = init_box[1] + init_box[3]
vis_image =cv2.rectangle(image[0],(ini_top,ini_left),(ini_bottom,ini_right),(255,0,0),2)

"""The initial bounding box is drawn on the first frame of the video, and the video is written to the file.

After that, for each frame in the boxes array, a bounding box is drawn on the corresponding frame using cv2.rectangle, and the video is updated using writer.write. Finally, the video is released and showing the tracking results by drawing the bounding box around the detected object on each frame.
"""

VIDEO_FILE_PATH ='/content/drive/MyDrive/ML/vid_ped.avi'
fourcc = cv2.VideoWriter_fourcc(*"XVID")
writer= cv2.VideoWriter(VIDEO_FILE_PATH,fourcc,30,(vis_image.shape[1],vis_image.shape[0]),True)
writer.write(vis_image[:,:,::-1])
for i,(x,y,w,h) in enumerate(boxes):
  if x != 0:
    vis_image = cv2.rectangle(image[i+1],(x,y),(x+w,y+h),(255,0,0),2)
    writer.write(vis_image[:,:,::-1])
writer.release()